5722018461	This evolution meant that interactions between user agents and origins servers were no longer uniform. Some of those interactions are merely instances of the Web's default publishing application. The only side effect of a typical GET that a human agent cares about is that the user can read another document (since users don't think about the Web in terms of resources and retrieved representation-states but, rather, as a way to read other people's documents). Of course, we have to distinguish between kinds and kinds of obligation for all of this to make any sense at all.When the AWWW says that safe interactions are ones by which human users incur no new obligations, what it really means is that some interactions have side effects which human users care about -- called "unsafe interactions" -- while other interactions do not have side effects which human users care about -- called "safe interactions". I think the distinction actually lies here, rather than between obligating and non-obligating interactions for the following reasons. First, human users may be obligated by merely reading a document. Second, retrieving representations obliges agents to observe, for example, all of the MUST NOTs and MUSTs of all of the relevant standards and specifications documents.The first case happens as a routine matter of modern life. Reading a subpoena or a divorce decree or a political tract or an email from an old lover -- all of these may be obligation-creating or obligation-incurring acts which are also naturally accomplished on the Web by means of "merely" retrieving a representation. And, yes, they are obligation-implicating in part because they are acts embedded within rich, complex non-Web webs of social significance and signification. But then so, too, is the AWWW's canonical example of a POST incurring a credit card debt. That protocol interaction is obligation-implicating in part because it is the enactment of a complex commercial relationship between a lender and a borrower.This discussion also suggests another distinction: the one between interactions which create (subscribing to a mailing list) and interactions which incur (charging a credit card) obligations. Does the AWWW really mean only incurring interactions?  I don't know, but I'll use the phrase "obligation-implicating" from here on since I think both are problematic.But perhaps the AWWW has some other, restricted sense of obligation in mind? The examples it gives all fall within a kind of restricted range: credit card charges, "subscribing to a newsletter, posting to a list, or modifying a database". (Isn't this last example particularly bad? If a web site logs accesses to a database, then my retrieving a representation modifies a database. But that's clearly not what the AWWW intends.) These are mostly unlike the examples of obligation-implicating acts I offered earlier. But it would be good for the AWWW to have some principled or at least clear way of distinguishing these kinds of obligation.Second, since the principle here is that "Agents do not incur obligations by retrieving a representation", it's not entirely clear whether the AWWW means human users or user agents (i.e., browsers) or both. The people who program user agents are at least weakly obligated to do so in such a way as to not violate the relevant standards and specifications when retrieving representations. It's a natural, even if anthropomorphizing way of speaking to say that user agents are obliged to follow the relevant standards when retrieving representations.At the very least, then, there is something useful to be said here about web publishers and web application developers being careful about what sorts of web interactions create side effects that human agents are likely to especially care about. This something is however very hard to state in terms of architectural principles.The problem here is that belated architectural elucidation is subject to a cruel tension. On the one hand, the Web is in place and it clearly works; but that doesn't necessarily mean it is architecturally or conceptually elegant in all of its parts. It could work better, of course, and there are specific practices to promote or demote so that the Web continues to work. On the other hand, when humans sit down to do something which they call an architecture of a complex system, we have need of conceptual elegance and a certain purity. Gross or even subtle violations of the various conceptual virtues strike us as reasons to think such an architecture could be improved. There is a tension, then, between the Web which is deployed and working and the ideal Web the principles of which the TAG has tried to conceptually elucidate.Thus far I've discussed the three chief principles of the Web's architecture: identification, interaction and representation. I then spent a few columns discussing identification, which is the source of everyone's favorite permathreads about URIs and resources. It's a cluster of interesting issues, but certainly not to everyone's taste or inclination.In this and the next column I will discuss the second fundamental web principle, namely interaction. Given that we have a means of identifying and conceptualizing web resources as nodes within a distributed, hypermedia information system, we need some means of interacting with them. The nodes of an information system do us no good if we or agents acting on our behalf cannot interact with them.While HTTP GET is the best known and most commonly used means of interacting with web resources, it is by no means the only way. One may use PUT to mutate the state of some resource, POST to create a new resource (or, more specifically, to add a new resource to an existing collection of web resources), DELETE to destroy an extant resource, and so on. In each of these cases what is happening, among other things, is that a user agent is "dereferencing the URI" -- this is a basic term of art in this area -- which identifies the resource in question.In the XML and web development communities we often talk casually about dereferencing URIs.  We talk as if dereferencing a URI is an atomic operation, and for most purposes that's precisely what it is. But, as the AWWW points out, what a user agent must do to dereference a URI is both specific to a URI scheme and often rather complex. It is a testament to the engineering practices of several, historically extended communities that dereferencing a URI may "involve a succession of steps as described in independent specifications", and that for the most part it just works.I won't walk through the AWWW's eight-step examination of a URI dereference, nor will I list the six or so relevant specifications that touch on this process. The important point is that it works, and that it is both less simple and more robust than it often seems.As the REST architectural style suggests, user agents on the Web don't really interact directly with resources. Rather they interact directly with representations of the states of resources, which are identified by URIs.Given the utility of the opacity of web identifiers it stands to reason that the protocol by means of which interactions between user agents and servers is structured includes provisions for transmitting metadata about the format of the retrieved representation.User agents send messages to servers, requesting, say, the retrieval of a representation. In response, servers pass messages back to the user agent in which the retrieved representation, together with metadata, may also be included. The protocols determining the Web's primary interactions are highly structured and rather complex.The AWWW conceptually decomposes a resource representation into two elementary parts: representation data and representation metadata. The representation data is the re-presentation of the state of some resource which the user agent requested. It is ideally structured according to some format, preferably one which is a standard. HTML and XML and RDF are three such standard representational formats.This brings us back to the puzzling issue from the previous column: an earlier draft of the AWWW said that, essentially, fragment identifiers are identifiers of parts of a resource-state representation. In other words, a URI identifies a resource and the fragment identifier part of that URI identifies part of the representation of the resource. So, for example, http://monkeyfist.com/kendall/xfmllib#download has (under one description) two parts: the fragment identifier and the rest of the URI. The URI identifies a resource which we might call "Kendall's page for the Python XFML library, xfmllib", and if you dereference that URI without the fragment identifier, you get an HTML representation of that resource. If you dereference it in a typical browser, you get that HTML representation, but your browser tries to find a named part of the representation called "#download". That URI identifies a URI and, then, a part of the representation of that resource.That is a rather clear, perhaps even elegant way of understanding fragment identifier semantics. It basically says that the interpretation of the fragment identifier is specific to the Internet Media Type of the retrieved representation which one gets when one dereferences the URI. Cool.First, I don't know what it means to "determine" a resource: secondary, primary or otherwise. I know what it means to dereference a URI, which is how I take it that one interacts with resources on the Web. I also know how to conceptualize the idea of a resource identifier pointing to or identifying some part or element of its retrieved representation, in a representation-relative way. Second, I find it deeply broken that one interacts with some kinds of web resources by dereferencing the URIs which identify them, while one interacts with other kinds of resources by doing something representation-specific in the context of the representation of the state of some